Past Sean, used to have to spin up a VM to then run WhisperAI, on Ubuntu, then I upgraded to Arch(Btw.), and I had some problems with the graphics card/Cuda
So what I want to do, is create a dockerfile that can run in the background, everytime I want to translate some Japanese speech(Locally - no internet, that's cheating) - 
Ideally it would be able to real time translaSeans and 'chunk' the audio in sections, then translate that, and save to a text file with timestamps - that's alot of moving parts 
worst case ontario, get it to take an audio file and translate that to a text document with timestamps would be the MVP
Also I want a hotkey that I can press like 'ctrl + [' to start recording and 'ctrl + ]' to stop recording and then translate everything within and print it out to a text file,
  do I want to save these files, or just have temporary ones? If I use temporary, would make the code way easier to write, less moving parts, if save, I would have records for future Sean - 
So if I have an interview/meeting, just start and stop recording when they are talking, and It will also double as a record of the convo, in case there is some Japanese I don't understand, can review later.
Since I previously had trouble with cuda, I would need to figure out how to give it access to the graphics card - model won't run without cuda, cuda won't run without a graphics card
I'm going to use AI to save time, as I'm currently studying math-precalc-EE-slovak-Japanese-coding-etc and I don't have weeks to sink into this, just spent weeks learning docker, the sooner I do this, the better
Probably use claude, as I've had really good success with it in the past, although OpenAI-Whisper is the model I will be putting in docker, would their proprietary AI be better at coding their own AI STT model? idk
Maybe I should start with the Coqui-AI-Model TTS - would be easier to work with, I've had that running pretty succesfully to create anki cards with speech in the past, already have half code written just need docker
On second thought, although it is nice, the Japanese STT model is way nicer to have, and get's me closer to being a samurai in animeland - although I can get citizenship by descent in slovakia-I can also do that later

Will need to create a prompt - mention dockerfile, all dependancies, openAI whisper, what model of python I need, and access to GPU
TO DO: 
-Create Prompt
-Create a 'Dockerfile'
  '.dockerignore' 
  '.gitignore' - don't want to upload a multi gig model to github accidently
-Make sure all dependancies are installed
-Ensure everything on host machine to allow docker container to access GPU/Cuda is installed - and all dependancies to record and share audios and code volumes
-Create a 'Commands' that will detail commands to launch and use the docker container/'docker-compose.yml'

1. Host Machine Requirements
First, install these on your host machine:
Docker
NVIDIA GPU Drivers
NVIDIA Container Toolkit (nvidia-docker2)
Install NVIDIA Container Toolkit:
# Add NVIDIA package repositories
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
# Install nvidia-docker2
sudo apt-get update
sudo apt-get install -y nvidia-docker2
# Restart Docker daemon
sudo systemctl restart docker

!ERROR! : Ran above command, and got this :
sudo: apt-key: command not found
tee: /etc/apt/sources.list.d/nvidia-docker.list: No such file or directory - Will fix later, my nvidia drivers work for steam/lutris, might work already
# Unsupported distribution!
# Check https://nvidia.github.io/nvidia-docker
zsh: command not found: #
sudo: apt-get: command not found
sudo: apt-get: command not found
zsh: command not found: #

2. Project Structure
whisper-jp/
├── src/                    # Your source code directory
├── recordings/             # Directory for audio recordings
├── output/                 # Directory for transcriptions
├── Dockerfile
├── .dockerignore
├── .gitignore
└── docker-compose.yml      # For easier container management

3. Dockerfile 
4. Docker Compose
version: '3.8'

services:
  whisper:
    build: .
    container_name: whisper-jp
    volumes:
      - ./src:/app/src
      - ./recordings:/app/recordings
      - ./output:/app/output
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

5. .dockerignore
6. .gitignore

2nd Prompt Results =======================================================================================================================================================================================
# I saved everything for the 'Dockerfile' '.gitignore' and '.dockerignore' from my previous prompt, the volumes and file structure was wrong, so trying again
/mnt/sdb4/Code/Pysean/Sean/JapaNaeS/STT-Whisper/Docker/
├── src/                    # Source code directory
│   ├── __init__.py
│   ├── main.py            # Main application code
│   ├── audio_handler.py   # Audio recording/processing
│   └── translator.py      # Translation logic
├── data/
│   ├── audio/            # Raw audio recordings
│   │   ├── temp/        # For real-time recording
│   │   └── saved/       # For saved recordings
│   └── output/          # Translated text files
│       ├── transcripts/ # Japanese transcripts
│       └── translations/ # English translations
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
├── .dockerignore
└── .gitignore
#changed 'Dockerfile', added 'docker-compose.yml' 'requirements.txt'
#created directories with below commands :
cd /mnt/sdb4/Code/Pysean/Sean/JapaNaeS/STT-Whisper/Docker
mkdir -p src data/audio/{temp,saved} data/output/{transcripts,translations}
touch data/audio/temp/.gitkeep data/audio/saved/.gitkeep \
      data/output/transcripts/.gitkeep data/output/translations/.gitkeep

#Host Machine Requirements - Just tried, one by one, not a a single one of these commands works,:
# Install NVIDIA drivers if not already installed
sudo ubuntu-drivers autoinstall
# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
#commands were for ubuntu, here are the new ones:
sudo pacman -S nvidia nvidia-utils
sudo pacman -S nvidia-container-toolkit #threw an error :
git clone https://aur.archlinux.org/nvidia-container-toolkit.git
cd nvidia-container-toolkit
makepkg -si
yay -S nvidia-container-toolkit
# All of the above commands for nvidia-container-toolkit errored out, pacman, yay, and git clone/makepkg :
error: failed retrieving file 'nvidia-container-toolkit-1.16.2-1-x86_64.pkg.tar.zst.sig' from ca.mirrors.cicku.me : The requested URL returned error: 404
warning: failed to retrieve some files

sudo pacman -Syu #something must be missing, doing a system update, it's been a few weeks I think
# Install nvidia-container-runtime
sudo pacman -S nvidia-container-runtime
# If that doesn't work, try these packages
sudo pacman -S nvidia-docker nvidia-container-toolkit
# If the above doesn't work, try installing from the AUR using these package names
yay -S nvidia-container-runtime-bin
# or
yay -S nvidia-container-toolkit-bin

4. Configure Docker to use NVIDIA runtime
#After successful installation, edit or create the Docker daemon configuration:
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<EOF
{
    "runtimes": {
        "nvidia": {
            "path": "/usr/bin/nvidia-container-runtime",
            "runtimeArgs": []
        }
    },
    "default-runtime": "nvidia"
}
EOF

#Restart docker:
sudo systemctl restart docker
#Test Install:
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

#Build and Run Container :
docker-compose build
docker-compose up -d

!Error! docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].

Docker isn't detecting GPU Drivers - I already put a day into this project, and spent last 2 hours attempting to debug, same error, 2 hours later, putting this down for now
I got too much other stuff on my plate atm to spend days debugging
https://hub.docker.com/r/nvidia/cuda
https://docs.docker.com/engine/containers/resource_constraints/#gpu
https://github.com/blakeblackshear/frigate/discussions/5536

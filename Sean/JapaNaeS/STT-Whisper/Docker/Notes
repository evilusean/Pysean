Past Sean, used to have to spin up a VM to then run WhisperAI, on Ubuntu, then I upgraded to Arch(Btw.), and I had some problems with the graphics card/Cuda
So what I want to do, is create a dockerfile that can run in the background, everytime I want to translate some Japanese speech(Locally - no internet, that's cheating) - 
Ideally it would be able to real time translaSeans and 'chunk' the audio in sections, then translate that, and save to a text file with timestamps - that's alot of moving parts 
worst case ontario, get it to take an audio file and translate that to a text document with timestamps would be the MVP
Also I want a hotkey that I can press like 'ctrl + [' to start recording and 'ctrl + ]' to stop recording and then translate everything within and print it out to a text file,
  do I want to save these files, or just have temporary ones? If I use temporary, would make the code way easier to write, less moving parts, if save, I would have records for future Sean - 
So if I have an interview/meeting, just start and stop recording when they are talking, and It will also double as a record of the convo, in case there is some Japanese I don't understand, can review later.
Since I previously had trouble with cuda, I would need to figure out how to give it access to the graphics card - model won't run without cuda, cuda won't run without a graphics card
I'm going to use AI to save time, as I'm currently studying math-precalc-EE-slovak-Japanese-coding-etc and I don't have weeks to sink into this, just spent weeks learning docker, the sooner I do this, the better
Probably use claude, as I've had really good success with it in the past, although OpenAI-Whisper is the model I will be putting in docker, would their proprietary AI be better at coding their own AI STT model? idk
Maybe I should start with the Coqui-AI-Model TTS - would be easier to work with, I've had that running pretty succesfully to create anki cards with speech in the past, already have half code written just need docker
On second thought, although it is nice, the Japanese STT model is way nicer to have, and get's me closer to being a samurai in animeland - although I can get citizenship by descent in slovakia-I can also do that later

Will need to create a prompt - mention dockerfile, all dependancies, openAI whisper, what model of python I need, and access to GPU
TO DO: 
-Create Prompt
-Create a 'Dockerfile'
  '.dockerignore' 
  '.gitignore' - don't want to upload a multi gig model to github accidently
-Make sure all dependancies are installed
-Ensure everything on host machine to allow docker container to access GPU/Cuda is installed

1. Host Machine Requirements
First, install these on your host machine:
Docker
NVIDIA GPU Drivers
NVIDIA Container Toolkit (nvidia-docker2)
Install NVIDIA Container Toolkit:
# Add NVIDIA package repositories
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
# Install nvidia-docker2
sudo apt-get update
sudo apt-get install -y nvidia-docker2
# Restart Docker daemon
sudo systemctl restart docker

!ERROR! : Ran above command, and got this :
sudo: apt-key: command not found
tee: /etc/apt/sources.list.d/nvidia-docker.list: No such file or directory - Will fix later, my nvidia drivers work for steam/lutris, might work already
# Unsupported distribution!
# Check https://nvidia.github.io/nvidia-docker
zsh: command not found: #
sudo: apt-get: command not found
sudo: apt-get: command not found
zsh: command not found: #

2. Project Structure
whisper-jp/
├── src/                    # Your source code directory
├── recordings/             # Directory for audio recordings
├── output/                 # Directory for transcriptions
├── Dockerfile
├── .dockerignore
├── .gitignore
└── docker-compose.yml      # For easier container management

3. Dockerfile 
# Use NVIDIA CUDA base image
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.9 \
    python3.9-distutils \
    python3-pip \
    ffmpeg \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip3 install --no-cache-dir \
    torch==2.0.1 \
    torchaudio==2.0.2 \
    numpy==1.24.3 \
    openai-whisper==20230918 \
    pykakasi==2.2.1 \
    transformers==4.31.0 \
    sentencepiece==0.1.99 \
    fugashi==1.2.1 \
    ipadic==1.0.0 \
    unidic-lite==1.0.8

# Create necessary directories
RUN mkdir -p /app/recordings /app/output

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app/src

# Volume mounting points
VOLUME ["/app/src", "/app/recordings", "/app/output"]

# Default command (can be overridden)
CMD ["python3", "-u", "/app/src/main.py"]

4. Docker Compose
version: '3.8'

services:
  whisper:
    build: .
    container_name: whisper-jp
    volumes:
      - ./src:/app/src
      - ./recordings:/app/recordings
      - ./output:/app/output
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

5. .dockerignore
.git
.gitignore
.env
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.pytest_cache/
.env
.venv
recordings/*
output/*

6. .gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Project specific
recordings/*
!recordings/.gitkeep
output/*
!output/.gitkeep

# Environment variables
.env

# Docker
.docker/

# Logs
*.log
